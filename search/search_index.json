{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"Hestia-GOOD <p>Computational tool for generating generalisation-evaluating evaluation sets.</p> <ul> <li>Documentation: https://ibm.github.io/Hestia-GOOD</li> <li>Source Code: https://github.com/IBM/Hestia-GOOD</li> <li>Paper [ICLR 2025]: https://openreview.net/pdf?id=qFZnAC4GHR</li> </ul>"},{"location":"#contents","title":"Contents","text":"Table of Contents <ul> <li>Intallation Guide</li> <li>Documentation</li> <li>Examples</li> <li>License </li> </ul> <p>## Installation </p> <p>Installing in a conda environment is recommended. For creating the environment, please run:</p> <pre><code>conda create -n hestia python\nconda activate hestia\n</code></pre>"},{"location":"#1-python-package","title":"1. Python Package","text":""},{"location":"#11from-pypi","title":"1.1.From PyPI","text":"<pre><code>pip install hestia-good\n</code></pre>"},{"location":"#12-directly-from-source","title":"1.2. Directly from source","text":"<pre><code>pip install git+https://github.com/IBM/Hestia-GOOD\n</code></pre>"},{"location":"#2-optional-dependencies","title":"2. Optional dependencies","text":""},{"location":"#21-molecular-similarity","title":"2.1. Molecular similarity","text":"<p>RDKit is a dependency necessary for calculating molecular similarities:</p> <pre><code>pip install rdkit\n</code></pre>"},{"location":"#22-sequence-alignment","title":"2.2. Sequence alignment","text":"<ul> <li>MMSeqs2 https://github.com/steineggerlab/mmseqs2 <pre><code># static build with AVX2 (fastest) (check using: cat /proc/cpuinfo | grep avx2)\nwget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH\n\n# static build with SSE4.1  (check using: cat /proc/cpuinfo | grep sse4)\nwget https://mmseqs.com/latest/mmseqs-linux-sse41.tar.gz; tar xvfz mmseqs-linux-sse41.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH\n\n# static build with SSE2 (slowest, for very old systems)  (check using: cat /proc/cpuinfo | grep sse2)\nwget https://mmseqs.com/latest/mmseqs-linux-sse2.tar.gz; tar xvfz mmseqs-linux-sse2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH\n\n# MacOS\nbrew install mmseqs2  \n</code></pre></li> </ul> <p>To use Needleman-Wunch, either:</p> <p><pre><code>conda install -c bioconda emboss\n</code></pre>   or</p> <pre><code>sudo apt install emboss\n</code></pre> <ul> <li>Windows: Download binaries from EMBOSS and MMSeqs2-latest</li> </ul>"},{"location":"#23-structure-alignment","title":"2.3. Structure alignment","text":"<ul> <li>To use Foldseek https://github.com/steineggerlab/foldseek:</li> </ul> <pre><code># Linux AVX2 build (check using: cat /proc/cpuinfo | grep avx2)\nwget https://mmseqs.com/foldseek/foldseek-linux-avx2.tar.gz; tar xvzf foldseek-linux-avx2.tar.gz; export PATH=$(pwd)/foldseek/bin/:$PATH\n\n# Linux SSE2 build (check using: cat /proc/cpuinfo | grep sse2)\nwget https://mmseqs.com/foldseek/foldseek-linux-sse2.tar.gz; tar xvzf foldseek-linux-sse2.tar.gz; export PATH=$(pwd)/foldseek/bin/:$PATH\n\n# Linux ARM64 build\nwget https://mmseqs.com/foldseek/foldseek-linux-arm64.tar.gz; tar xvzf foldseek-linux-arm64.tar.gz; export PATH=$(pwd)/foldseek/bin/:$PATH\n\n# MacOS\nwget https://mmseqs.com/foldseek/foldseek-osx-universal.tar.gz; tar xvzf foldseek-osx-universal.tar.gz; export PATH=$(pwd)/foldseek/bin/:$PATH\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#1-datasetgenerator","title":"1. DatasetGenerator","text":"<p>The HestiaGenerator allows for the easy generation of training/validation/evaluation partitions with different similarity thresholds. Enabling the estimation of model generalisation capabilities. It also allows for the calculation of the AU-GOOD (Area Under the Generalization Out-Of-Distribution curve). More information in Dataset Generator docs.</p> <pre><code>from hestia.dataset_generator import HestiaGenerator, SimArguments\n\n# Initialise the generator for a DataFrame\ngenerator = HestiaGenerator(df)\n\n# Define the similarity arguments (for more info see the documentation page https://ibm.github.io/Hestia-OOD/datasetgenerator)\n\n# Similarity arguments for protein similarity\nprot_args = SimArguments(\n    data_type='sequence', field_name='sequence',\n    alignment_algorithm='mmseqs2+prefilter', verbose=3\n)\n\n# Similarity arguments for molecular similarity\nmol_args = SimArguments(\n    data_type='small molecule', field_name='SMILES',\n    fingeprint='mapc', radius=2, bits=2048\n)\n\n# Calculate the similarity\ngenerator.calculate_similarity(prot_args)\n\n# Calculate partitions\ngenerator.calculate_partitions(min_threshold=0.3,\n                               threshold_step=0.05,\n                               test_size=0.2, valid_size=0.1)\n\n# Save partitions\ngenerator.save_precalculated('precalculated_partitions.gz')\n\n# Load pre-calculated partitions\ngenerator.from_precalculated('precalculated_partitions.gz')\n\n# Training code (filter partitions with test sets less than 18.5% of total data)\n\nfor threshold, partition in generator.get_partitions(filter=0.185):\n    train = df.iloc[partition['train']]\n    valid = df.iloc[partition['valid']]\n    test = df.iloc[partition['test']]\n\n# ...\n\n# Calculate AU-GOOD\ngenerator.calculate_augood(results, 'test_mcc')\n\n# Plot GOOD\ngenerator.plot_good(results, 'test_mcc')\n\n# Compare two models\nresults = {'model A': [values_A], 'model B': [values_B]}\ngenerator.compare_models(results, statistical_test='wilcoxon')\n</code></pre>"},{"location":"#2-similarity-calculation","title":"2. Similarity calculation","text":"<p>Calculating pairwise similarity between the entities within a DataFrame <code>df_query</code> or between two DataFrames <code>df_query</code> and <code>df_target</code> can be achieved through the <code>calculate_similarity</code> function. More details about similarity calculation can be found in the Similarity calculation documentation.</p> <pre><code>from hestia.similarity import sequence_similarity_mmseqs\nimport pandas as pd\n\ndf_query = pd.read_csv('example.csv')\n\n# The CSV file needs to have a column describing the entities, i.e., their sequence, their SMILES, or a path to their PDB structure.\n# This column corresponds to `field_name` in the function.\n\nsim_df = sequence_similarity_mmseqs(df_query, field_name='sequence', prefilter=True)\n</code></pre>"},{"location":"#3-clustering","title":"3. Clustering","text":"<p>Clustering the entities within a DataFrame <code>df</code> can be achieved through the <code>generate_clusters</code> function. There are three clustering algorithms currently supported: <code>CDHIT</code>, <code>greedy_cover_set</code>, or <code>connected_components</code>. More details about clustering can be found in the Clustering documentation.</p> <pre><code>from hestia.similarity import sequence_similarity_mmseqs\nfrom hestia.clustering import generate_clusters\nimport pandas as pd\n\ndf = pd.read_csv('example.csv')\nsim_df = sequence_similarity_mmseqs(df, field_name='sequence')\nclusters_df = generate_clusters(df, field_name='sequence', sim_df=sim_df,\n                                cluster_algorithm='CDHIT')\n</code></pre>"},{"location":"#4-partitioning","title":"4. Partitioning","text":"<p>Partitioning the entities within a DataFrame <code>df</code> into a training and an evaluation subsets can be achieved through 4 different functions: <code>ccpart</code>, <code>graph_part</code>, <code>reduction_partition</code>, and <code>random_partition</code>. More details about partitioing algorithms can be found in Partitionind documentation. An example of how <code>cc_part</code> would be used is:</p> <pre><code>from hestia.similarity import sequence_similarity_mmseqs\nfrom hestia.partition import ccpart\nimport pandas as pd\n\ndf = pd.read_csv('example.csv')\nsim_df = sequence_similarity_mmseqs(df, field_name='sequence')\ntrain, test, partition_labs = cc_part(df, threshold=0.3, test_size=0.2, sim_df=sim_df)\n\ntrain_df = df.iloc[train, :]\ntest_df = df.iloc[test, :]\n</code></pre>"},{"location":"#license","title":"License","text":"<p>Hestia is an open-source software licensed under the MIT Clause License. Check the details in the LICENSE file.</p>"},{"location":"clustering/","title":"Clustering","text":""},{"location":"clustering/#hestia.clustering.generate_clusters","title":"<code>generate_clusters(df, field_name, sim_df, threshold=0.4, verbose=0, cluster_algorithm='greedy_incremental', filter_smaller=True, **kwargs)</code>","text":"<p>Generates clusters from a DataFrame.</p> <p>This function supports several clustering algorithms that operate on pairwise similarity data. Each algorithm has different scalability, behavior, and underlying assumptions. Below is a summary of the available algorithms:</p> <p>Clustering algorithms:     - <code>CDHIT</code> or <code>greedy_incremental</code>:         Greedy incremental clustering similar to CD-HIT. Entities are         sorted by length, and each new element seeds a cluster; all items         above the similarity threshold are assigned to the same cluster.         Fast, deterministic, and suitable for sequence-length-dependent         ordering.</p> <pre><code>- `greedy_cover_set` or `butina`:\n    A greedy set-cover\u2013style approach (similar to Butina clustering).\n    Selects items with the largest number of neighbors above the\n    threshold and forms clusters around them. Tends to produce compact,\n    high-similarity groups.\n\n- `connected_components`:\n    Treats similarity relations above the threshold as graph edges and\n    computes connected components. All entities connected (directly or\n    transitively) via similarity \u2265 threshold belong to the same\n    cluster. Very fast and stable for large sparse similarity graphs.\n\n- `bitbirch`:\n    Clustering based on the BitBirch tree/hashing algorithm. Supports\n    two modes:\n        (1) fingerprint-based (e.g. SMILES \u2192 Morgan fingerprints), or\n        (2) similarity-matrix-derived.\n    Scales efficiently to large datasets and creates hierarchical,\n    radius-based clusters.\n\n- `umap`:\n    Reduces high-dimensional fingerprints or similarity matrices into a\n    low-dimensional manifold using UMAP, then applies agglomerative\n    clustering. Useful when clusters are better separated in embedded\n    space than in raw feature or similarity space.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with entities to cluster.</p> required <code>field_name</code> <code>str</code> <p>Name of the field with the entity information (e.g., <code>protein_sequence</code> or <code>structure_path</code>), defaults to 'sequence'.</p> required <code>threshold</code> <code>float</code> <p>Similarity value above which entities will be considered similar, defaults to 0.4</p> <code>0.4</code> <code>sim_df</code> <code>DataFrame</code> <p>DataFrame with similarities (<code>metric</code>) between <code>query</code> and <code>target</code>, it is the product of <code>calculate_similarity</code> function</p> required <code>verbose</code> <code>int</code> <p>How much information will be displayed. Options:     - 0: Errors,     - 1: Warnings,     - 2: All Defaults to 0</p> <code>0</code> <code>cluster_algorithm</code> <code>str</code> <p>Clustering algorithm to use. Options:     - <code>CDHIT</code> or <code>greedy_incremental</code>     - <code>greedy_cover_set</code>     - <code>connected_components</code>     - <code>bitbirch</code>     - <code>umap</code></p> <p>Defaults to \"greedy_incremental\".</p> <code>'greedy_incremental'</code> <code>filter_smaller</code> <code>Optional[bool]</code> <p>Whether to filter smaller indices when constructing adjacency matrices in similarity-based algorithms, defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>np.ndarray</code> <p>DataFrame with entities and the cluster they belong to.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Clustering algorithm is not supported</p>"},{"location":"dataset_generator/","title":"Dataset Generator","text":""},{"location":"dataset_generator/#hestia.dataset_generator.HestiaGenerator","title":"<code>HestiaGenerator(data, verbose=True)</code>","text":"<p>Class for generating multiple Dataset partitions for generalisation evaluation.</p> <p>Initialise class</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>DataFrame with the original data from which datasets will be generated.</p> required"},{"location":"dataset_generator/#hestia.dataset_generator.HestiaGenerator.calculate_augood","title":"<code>calculate_augood(results, target_df, target_field_name, target_embds=None, return_weights=False)</code>","text":"<p>Calculate the 'area under the GOOD curve' (AU-GOOD) metric.</p> <p>This function calculates an AU-GOOD score by computing a weighted metric from similarity values obtained by comparing target deployment distribution to the training distribution. It returns both the weighted GOOD curve values and the AU-GOOD score.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Dict[float, float]</code> <p>A dictionary where keys are bins or thresholds (float) and values are metrics or counts associated with each bin.</p> required <code>target_df</code> <code>DataFrame</code> <p>A DataFrame containing the target data for similarity comparison. The column specified by <code>target_field_name</code> will be used to populate the similarity arguments for comparison.</p> required <code>target_field_name</code> <code>Optional[str]</code> <p>Name of the field in <code>target_df</code> that contains target values for comparison.</p> required <code>target_embds</code> <code>Optional[ndarray]</code> <p>A NumPy array containing the target embeddings for similarity calculation.</p> <code>None</code> <code>return_weights</code> <code>bool</code> <p>Return histogram values for train-deployment similarities</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Tuple[np.ndarray, float], Tuple[np.ndarray, float, np.ndarray]]</code> <p>A tuple containing: - <code>good_curve</code> (np.ndarray): Array of weighted values representing the GOOD curve. - <code>au_good</code> (float): The calculated area under the GOOD curve. and optionally: - <code>weights</code> (np.ndarray): Array of weights representing train-deployment similarities</p>"},{"location":"dataset_generator/#hestia.dataset_generator.HestiaGenerator.calculate_partitions","title":"<code>calculate_partitions(sim_args=None, sim_df=None, label_name=None, label_bins=10, min_threshold=0.0, threshold_step=0.05, test_size=0.2, valid_size=0.1, partition_algorithm='ccpart', random_state=42, verbose=1, n_partitions=None)</code>","text":"<p>Calculates multiple partitions of a dataset for training, validation, and testing based on sequence similarity. Supports the following partitioning algorithms: <code>ccpart</code>, <code>graph_part</code>, and <code>butina</code>. Additionally, it computes partitions for  different similarity thresholds and random partitions.</p> <p>:example:</p>"},{"location":"dataset_generator/#hestia.dataset_generator.HestiaGenerator.calculate_partitions--example-of-partitioning-with-a-similarity-threshold-of-03-and-a-test-size-of-02","title":"Example of partitioning with a similarity threshold of 0.3 and a test size of 0.2","text":"<p>partitions = calculate_partitions(     sim_args=similarity_args,     label_name='Y',     min_threshold=0.2,     threshold_step=0.05,     test_size=0.2,     partition_algorithm='ccpart',     random_state=42 )</p>"},{"location":"dataset_generator/#hestia.dataset_generator.HestiaGenerator.calculate_partitions--accessing-the-partitions-for-a-specific-threshold","title":"Accessing the partitions for a specific threshold","text":"<p>train_set = partitions[0.3]['train'] valid_set = partitions[0.3]['valid'] test_set = partitions[0.3]['test']</p> <p>Parameters:</p> Name Type Description Default <code>sim_args</code> <code>Optional[SimArguments]</code> <p>Object containing the similarity parameters for partitioning. This includes options for  calculating sequence similarity, such as the alignment method and similarity threshold. Defaults to None.</p> <code>None</code> <code>sim_df</code> <code>Optional[Union[DataFrame, DataFrame]]</code> <p>Precomputed similarity DataFrame. If None, the similarity will be calculated using <code>sim_args</code>.</p> <code>None</code> <code>label_name</code> <code>Optional[str]</code> <p>The name of the label column for the dataset. Defaults to None.</p> <code>None</code> <code>label_bins</code> <code>Optional[int]</code> <p>Number of bins to discretize the label, if the label is continuous (regression). Only with <code>partition_algorithm</code>: <code>ccpart</code>, <code>ccpart_random</code>.</p> <code>10</code> <code>min_threshold</code> <code>Optional[float]</code> <p>The minimum similarity threshold to start partitioning. Defaults to 0.0.</p> <code>0.0</code> <code>threshold_step</code> <code>Optional[float]</code> <p>The step size for varying the similarity threshold during partitioning. Defaults to 0.05.</p> <code>0.05</code> <code>test_size</code> <code>Optional[float]</code> <p>The proportion of the dataset to allocate to the test set. Defaults to 0.2.</p> <code>0.2</code> <code>valid_size</code> <code>Optional[float]</code> <p>The proportion of the training set to allocate to the validation set. Defaults to 0.1.</p> <code>0.1</code> <code>verbose</code> <code>int</code> <p>Verbosity level for process logging, where higher values increase output detail.</p> <code>1</code> <code>partition_algorithm</code> <code>Optional[str]</code> <p>The partitioning algorithm to use. Options are: - <code>'ccpart'</code>: Connected components algorithm that puts in testing the smallest unconnected clusters. - <code>'graph_part'</code>: GraphPart partitioning. - <code>'ccpart_random'</code>: Connected components algorithm that puts in testing random clusters. - <code>'sim_umap'</code>: Similarity matrix UMAP. - <code>'butina'</code>: Butina working on similarity matrices. Defaults to <code>'ccpart'</code>.</p> <code>'ccpart'</code> <code>random_state</code> <code>Optional[int]</code> <p>The random seed for reproducibility. Defaults to 42.</p> <code>42</code> <code>n_partitions</code> <code>Optional[int]</code> <p>The number of partitions to create when using <code>graph_part</code>. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the partitions for each threshold. The dictionary has keys: - <code>train</code>: DataFrame for the training set. - <code>valid</code>: DataFrame for the validation set. - <code>test</code>: DataFrame for the test set. - <code>clusters</code>: The clusters formed by the partitioning algorithm. - For random partitions, the key <code>'random'</code> will contain the train, valid, and test sets.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an unsupported partition algorithm is specified.</p>"},{"location":"dataset_generator/#hestia.dataset_generator.HestiaGenerator.calculate_similarity","title":"<code>calculate_similarity(sim_args)</code>","text":"<p>Calculate pairwise similarity between all the elements in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>sim_args</code> <code>SimArguments</code> <p>See similarity arguments entry.</p> required"},{"location":"dataset_generator/#hestia.dataset_generator.HestiaGenerator.compare_models","title":"<code>compare_models(model_results, statistical_test='wilcoxon')</code>  <code>staticmethod</code>","text":"<p>Compare the generalisation capabilities of n models against each other, providing p-values for every possible pair of models measuring how likely is model A to be better performing than model B.</p> <p>Parameters:</p> Name Type Description Default <code>model_results</code> <code>Dict[str, Union[List[float], ndarray]]</code> <p>Dictionary with model name as key and a list with the ordered performance values of the model at different thresholds.</p> required <code>statistical_test</code> <code>str</code> <p>Statistical test to compute the model differences. Currently supported: - <code>wilcoxon</code>: Wilcoxon ranked-sum test Defaults to 'wilcoxon'</p> <code>'wilcoxon'</code>"},{"location":"dataset_generator/#hestia.dataset_generator.HestiaGenerator.from_precalculated","title":"<code>from_precalculated(data_path)</code>","text":"<p>Load partition indexes if they have already being calculated.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>str</code> <p>Path to saved partition indexes.</p> required"},{"location":"dataset_generator/#hestia.dataset_generator.HestiaGenerator.load_similarity","title":"<code>load_similarity(output_path)</code>","text":"<p>Load similarity calculation from file.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>str</code> <p>File with similarity calculations.</p> required"},{"location":"dataset_generator/#hestia.dataset_generator.HestiaGenerator.save_precalculated","title":"<code>save_precalculated(output_path, include_metada=True)</code>","text":"<p>Save partition indexes to disk for quickier re-running.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>str</code> <p>Path where partition indexes should be saved.</p> required"},{"location":"dataset_generator/#hestia.dataset_generator.SimArguments","title":"<code>SimArguments(data_type='sequence', field_name='sequence', min_threshold=0.0, threads=cpu_count(), verbose=0, save_alignment=False, filename='alignment', sim_function=None, bits=None, radius=None, fingerprint=None, denominator=None, representation=None, prefilter=None, alignment_algorithm=None, query_embds=None, target_embds=None, target_df=None, needle_config=None, **kwargs)</code>","text":"<p>Dataclass with the inputs for similarity calculation.</p>"},{"location":"partition/","title":"Partitioning algorithms","text":""},{"location":"partition/#hestia.partition.bitbirch","title":"<code>bitbirch(df, sim_df=None, field_name=None, label_name=None, test_size=0.2, valid_size=0.0, threshold=0.3, verbose=0, branching_factor=50, n_bins=10, radius=2, bits=1024, n_clusters=20, **kwargs)</code>","text":"<p>Partition a dataset using the BitBirch clustering algorithm.</p> <p>Generates clusters based on molecular features or similarity using the BitBirch algorithm. Labels can be optionally discretized for balancing, and the dataset is partitioned into train/test/validation subsets using <code>smallest_assignment</code>. Prints warnings if the partition sizes deviate from expectations.</p> <p>Reference: P\u00e9rez KL, Jung V, Chen L, Huddleston K, Miranda-Quintana RA. BitBIRCH: efficient clustering of large molecular libraries. Digital Discovery. 2025;4(4):1042-51.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing molecular entities.</p> required <code>sim_df</code> <code>DataFrame</code> <p>Optional DataFrame containing pairwise similarity scores between entities, defaults to None.</p> <code>None</code> <code>field_name</code> <code>str</code> <p>Optional column name used for clustering.</p> <code>None</code> <code>label_name</code> <code>str</code> <p>Optional column name for labels used for balancing, defaults to None.</p> <code>None</code> <code>test_size</code> <code>float</code> <p>Proportion of entities to allocate to the test subset, defaults to 0.2.</p> <code>0.2</code> <code>valid_size</code> <code>float</code> <p>Proportion of entities to allocate to the validation subset, defaults to 0.0.</p> <code>0.0</code> <code>threshold</code> <code>float</code> <p>Similarity threshold used for clustering, defaults to 0.3.</p> <code>0.3</code> <code>verbose</code> <code>int</code> <p>Verbosity level. Higher values print detailed partition proportions, defaults to 0.</p> <code>0</code> <code>branching_factor</code> <code>int</code> <p>Branching factor for BitBirch clustering, defaults to 50.</p> <code>50</code> <code>n_bins</code> <code>int</code> <p>Number of bins used when discretizing labels for balancing, defaults to 10.</p> <code>10</code> <code>radius</code> <code>int</code> <p>Neighborhood radius for BitBirch clustering, defaults to 2.</p> <code>2</code> <code>bits</code> <code>int</code> <p>Number of bits used in fingerprint representation, defaults to 1024.</p> <code>1024</code> <code>n_clusters</code> <code>int</code> <p>Number of clusters to generate, defaults to 20.</p> <code>20</code> <p>Returns:</p> Type Description <code>Union[     Tuple[List[int], List[int], List[int], np.ndarray],     Tuple[List[int], List[int], np.ndarray] ]</code> <p>If <code>valid_size &gt; 0</code> returns train, test, valid subsets plus cluster assignments. Otherwise returns train, test subsets plus cluster assignments.</p>"},{"location":"partition/#hestia.partition.butina","title":"<code>butina(df, sim_df, field_name=None, label_name=None, test_size=0.2, valid_size=0.0, threshold=0.3, verbose=0, n_bins=10, filter_smaller=True)</code>","text":"<p>Partition a dataset using a Butina-style greedy clustering algorithm.</p> <p>Generates clusters based on molecular similarity using a greedy cover set approach (Butina clustering). Labels can be optionally discretized for balancing, and the dataset is partitioned into train/test/validation subsets using <code>smallest_assignment</code>. Prints warnings if the partition sizes deviate from expectations.</p> <p>Generalized to work on similarity matrices rather than fingerprints directly.</p> <p>Reference: Butina D. Unsupervised data base clustering based on daylight's fingerprint and Tanimoto similarity: A fast and automated way to cluster small and large data sets. Journal of Chemical Information and Computer Sciences. 1999 Jul 26;39(4):747-50.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing molecular entities.</p> required <code>sim_df</code> <code>DataFrame</code> <p>DataFrame or matrix containing pairwise similarity scores between entities.</p> required <code>field_name</code> <code>str</code> <p>Optional column name used for clustering. If None, clustering is based solely on <code>sim_df</code>.</p> <code>None</code> <code>label_name</code> <code>str</code> <p>Optional column name for labels used for balancing, defaults to <code>None</code>.</p> <code>None</code> <code>test_size</code> <code>float</code> <p>Proportion of entities to allocate to the test subset, defaults to 0.2.</p> <code>0.2</code> <code>valid_size</code> <code>float</code> <p>Proportion of entities to allocate to the validation subset, defaults to 0.0.</p> <code>0.0</code> <code>threshold</code> <code>float</code> <p>Similarity threshold used for cluster formation, defaults to 0.3.</p> <code>0.3</code> <code>verbose</code> <code>int</code> <p>Verbosity level. Higher values print detailed partition proportions, defaults to 0.</p> <code>0</code> <code>n_bins</code> <code>int</code> <p>Number of bins used when discretizing labels for balancing, defaults to 10.</p> <code>10</code> <code>filter_smaller</code> <code>Optional[bool]</code> <p>Whether to filter smaller similarity values during clustering, defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[     Tuple[List[int], List[int], List[int], np.ndarray],     Tuple[List[int], List[int], np.ndarray] ]</code> <p>If <code>valid_size &gt; 0</code> returns train, test, valid subsets plus cluster assignments. Otherwise returns train, test subsets plus cluster assignments.</p>"},{"location":"partition/#hestia.partition.ccpart","title":"<code>ccpart(df, sim_df, field_name=None, label_name=None, test_size=0.2, valid_size=0.0, threshold=0.3, verbose=0, n_bins=10, filter_smaller=True)</code>","text":"<p>Partitions a dataset into training, testing, and optional validation sets based on connected  component clustering using a similarity matrix. Ensures clusters are kept intact across splits  and optionally balances label distributions across partitions. Smallest clusters are iteratively assigned to testing.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing the dataset to be partitioned.</p> required <code>sim_df</code> <code>DataFrame</code> <p>DataFrame representing precomputed pairwise similarities between samples.</p> required <code>field_name</code> <code>str</code> <p>Name of the column in <code>df</code> used for clustering; if None, uses <code>sim_df</code> directly.</p> <code>None</code> <code>label_name</code> <code>str</code> <p>Name of the label column for balancing partitions; if None, no balancing is performed.</p> <code>None</code> <code>test_size</code> <code>float</code> <p>Fraction of the dataset to allocate to the test set.</p> <code>0.2</code> <code>valid_size</code> <code>float</code> <p>Fraction of the dataset to allocate to the validation set; set to 0.0 to skip validation split.</p> <code>0.0</code> <code>threshold</code> <code>float</code> <p>Similarity threshold for connecting components when clustering.</p> <code>0.3</code> <code>verbose</code> <code>int</code> <p>Verbosity level for logging (higher values provide more detailed output).</p> <code>0</code> <code>n_bins</code> <code>int</code> <p>Number of bins to discretize continuous labels into for balancing purposes.</p> <code>10</code> <code>filter_smaller</code> <code>Optional[bool]</code> <p>Whether with the similarity metric less is less similar.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[Tuple[list, list, list], Tuple[list, list, list, list]]</code> <ul> <li>If <code>valid_size &gt; 0</code>: returns (train_indices, test_indices, valid_indices, cluster_assignments)</li> <li>Otherwise: returns (train_indices, test_indices, cluster_assignments)</li> </ul>"},{"location":"partition/#hestia.partition.ccpart_random","title":"<code>ccpart_random(df, sim_df, field_name=None, label_name=None, test_size=0.2, valid_size=0.0, threshold=0.3, verbose=0, seed=0, n_bins=10, filter_smaller=True)</code>","text":"<p>Partitions a dataset into training, testing, and optional validation sets based on connected  component clustering using a similarity matrix. Ensures clusters are kept intact across splits  and optionally balances label distributions across partitions. Cluesters are assigned to  testing randomly.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing the dataset to be partitioned.</p> required <code>sim_df</code> <code>DataFrame</code> <p>DataFrame representing precomputed pairwise similarities between samples.</p> required <code>field_name</code> <code>str</code> <p>Name of the column in <code>df</code> used for clustering; if None, uses <code>sim_df</code> directly.</p> <code>None</code> <code>label_name</code> <code>str</code> <p>Name of the label column for balancing partitions; if None, no balancing is performed.</p> <code>None</code> <code>test_size</code> <code>float</code> <p>Fraction of the dataset to allocate to the test set.</p> <code>0.2</code> <code>valid_size</code> <code>float</code> <p>Fraction of the dataset to allocate to the validation set; set to 0.0 to skip validation split.</p> <code>0.0</code> <code>threshold</code> <code>float</code> <p>Similarity threshold for connecting components when clustering.</p> <code>0.3</code> <code>verbose</code> <code>int</code> <p>Verbosity level for logging (higher values provide more detailed output).</p> <code>0</code> <code>n_bins</code> <code>int</code> <p>Number of bins to discretize continuous labels into for balancing purposes.</p> <code>10</code> <code>filter_smaller</code> <code>Optional[bool]</code> <p>Whether with the similarity metric less is less similar.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[Tuple[list, list, list], Tuple[list, list, list, list]]</code> <ul> <li>If <code>valid_size &gt; 0</code>: returns (train_indices, test_indices, valid_indices, cluster_assignments)</li> <li>Otherwise: returns (train_indices, test_indices, cluster_assignments)</li> </ul>"},{"location":"partition/#hestia.partition.cdhit_part","title":"<code>cdhit_part(df, sim_df, field_name=None, label_name=None, test_size=0.2, valid_size=0.0, threshold=0.3, verbose=0, n_bins=10, filter_smaller=True)</code>","text":"<p>Partitions a dataset into training, testing, and optional validation sets based on connected  component clustering using a similarity matrix. Ensures clusters are kept intact across splits  and optionally balances label distributions across partitions. Smallest clusters are iteratively assigned to testing.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing the dataset to be partitioned.</p> required <code>sim_df</code> <code>DataFrame</code> <p>DataFrame representing precomputed pairwise similarities between samples.</p> required <code>field_name</code> <code>str</code> <p>Name of the column in <code>df</code> used for clustering; if None, uses <code>sim_df</code> directly.</p> <code>None</code> <code>label_name</code> <code>str</code> <p>Name of the label column for balancing partitions; if None, no balancing is performed.</p> <code>None</code> <code>test_size</code> <code>float</code> <p>Fraction of the dataset to allocate to the test set.</p> <code>0.2</code> <code>valid_size</code> <code>float</code> <p>Fraction of the dataset to allocate to the validation set; set to 0.0 to skip validation split.</p> <code>0.0</code> <code>threshold</code> <code>float</code> <p>Similarity threshold for connecting components when clustering.</p> <code>0.3</code> <code>verbose</code> <code>int</code> <p>Verbosity level for logging (higher values provide more detailed output).</p> <code>0</code> <code>n_bins</code> <code>int</code> <p>Number of bins to discretize continuous labels into for balancing purposes.</p> <code>10</code> <code>filter_smaller</code> <code>Optional[bool]</code> <p>Whether with the similarity metric less is less similar.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[Tuple[list, list, list], Tuple[list, list, list, list]]</code> <ul> <li>If <code>valid_size &gt; 0</code>: returns (train_indices, test_indices, valid_indices, cluster_assignments)</li> <li>Otherwise: returns (train_indices, test_indices, cluster_assignments)</li> </ul>"},{"location":"partition/#hestia.partition.graph_part","title":"<code>graph_part(df, sim_df, label_name=None, test_size=0.0, valid_size=0.0, threshold=0.3, verbose=2, n_parts=10, filter_smaller=True)</code>","text":"<p>Builds a graph from the provided similarity matrix, applies a limited agglomerative clustering algorithm, balances clusters across partitions, and performs iterative reassignment to minimize forbidden edges. The final output can optionally be split into train/test/validation subsets based on cluster proportions.</p> <p>Reference: Teufel F, G\u00edslason MH, Almagro Armenteros JJ, Johansen AR, Winther O, Nielsen H. GraphPart: homology partitioning for biological sequence analysis. NAR genomics and bioinformatics. 2023 Dec 1;5(4):lqad088.</p> <p>Code adapted and generalized from the project Github repository: https://github.com/graph-part/graph-part</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing the entities to partition.</p> required <code>sim_df</code> <code>DataFrame</code> <p>Pairwise similarity DataFrame used to build the graph.</p> required <code>label_name</code> <code>str</code> <p>Optional column name containing entity labels used to guide cluster assignment for balancing, defaults to <code>None</code>.</p> <code>None</code> <code>test_size</code> <code>float</code> <p>Proportion of entities to allocate to the test split, defaults to <code>0.0</code>.</p> <code>0.0</code> <code>valid_size</code> <code>float</code> <p>Proportion of entities to allocate to the validation split (applied only after test split assignment), defaults to <code>0.0</code>.</p> <code>0.0</code> <code>threshold</code> <code>float</code> <p>Similarity threshold used to define edges in the graph and guide clustering, defaults to <code>0.3</code>.</p> <code>0.3</code> <code>verbose</code> <code>int</code> <p>Verbosity level. Values above 1 enable progress information, defaults to <code>2</code>.</p> <code>2</code> <code>n_parts</code> <code>int</code> <p>Number of partitions (clusters) to generate, defaults to <code>10</code>.</p> <code>10</code> <code>filter_smaller</code> <code>Optional[bool]</code> <p>If <code>True</code>, edges with similarity &gt;= threshold are kept. If <code>False</code>, edges &lt;= threshold are kept instead, defaults to <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[     np.ndarray,     Tuple[List[int], List[int], np.ndarray],     Tuple[List[int], List[int], List[int], np.ndarray] ]</code> <p>If <code>test_size</code> and <code>valid_size</code> are both <code>0.0</code>, returns an array of partition assignments (with <code>-1</code> for removed nodes). Otherwise returns train/test or train/test/valid index lists along with full cluster labels.</p>"},{"location":"partition/#hestia.partition.random_partition","title":"<code>random_partition(df, test_size, random_state=42, **kwargs)</code>","text":"<p>Use random partitioning algorithm to generate training and evaluation subsets. Wrapper around the <code>train_test_split</code> function from scikit-learn.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with the entities to partition</p> required <code>test_size</code> <code>float</code> <p>Proportion of entities to be allocated to test subset, defaults to 0.2</p> required <code>random_state</code> <code>int</code> <p>Seed for pseudo-random number generator algorithm, defaults to 42</p> <code>42</code> <p>Returns:</p> Type Description <code>Tuple[pd.DataFrame, pd.DataFrame]</code> <p>A tuple with the indexes of training and evaluation samples.</p>"},{"location":"partition/#hestia.partition.scaffold","title":"<code>scaffold(df, field_name, label_name=None, test_size=0.0, valid_size=0.0, n_bins=10, verbose=1)</code>","text":"<p>Partition a dataset based on Bemis-Murcko scaffolds.</p> <p>Generates Bemis-Murcko scaffolds from the molecular SMILES in <code>field_name</code> and assigns clusters based on unique scaffolds. Optionally discretizes labels for balancing and partitions the dataset into train/test/validation subsets using <code>smallest_assignment</code>. Prints warnings if partition sizes deviate significantly from expectations.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing molecular data.</p> required <code>field_name</code> <code>str</code> <p>Column name containing SMILES strings used to generate scaffolds.</p> required <code>label_name</code> <code>str</code> <p>Optional column name containing labels used for balancing, defaults to <code>None</code>.</p> <code>None</code> <code>test_size</code> <code>float</code> <p>Proportion of entities to allocate to the test subset, defaults to <code>0.0</code>.</p> <code>0.0</code> <code>valid_size</code> <code>float</code> <p>Proportion of entities to allocate to the validation subset, defaults to <code>0.0</code>.</p> <code>0.0</code> <code>n_bins</code> <code>int</code> <p>Number of bins used when discretizing labels for balancing, defaults to <code>10</code>.</p> <code>10</code> <code>verbose</code> <code>int</code> <p>Verbosity level. When <code>&gt; 2</code> prints detailed proportions, defaults to <code>1</code>.</p> <code>1</code> <p>Returns:</p> Type Description <code>Union[     Tuple[List[int], List[int], List[int], np.ndarray],     Tuple[List[int], List[int], np.ndarray] ]</code> <p>If <code>valid_size &gt; 0</code> returns train, test, valid subsets plus cluster assignments. Otherwise returns train, test subsets plus cluster assignments.</p>"},{"location":"partition/#hestia.partition.sim_umap","title":"<code>sim_umap(df, sim_df, field_name=None, label_name=None, test_size=0.0, valid_size=0.0, threshold=0.3, verbose=2, n_clusters=10, n_neighbors=15, n_components=2, n_pcs=50, min_dist=0.1, boolean_out=True, n_bins=10)</code>","text":"<p>UMAP-based partitioning using an external similarity matrix.</p> <p>It's a generalization of the <code>UMAP_original</code> algorithm from Guo et al., 2025, but extended to work on similarity matrices, instead of binary fingerprints.</p> <p>Generates clusters using UMAP while incorporating an external similarity matrix (<code>sim_df</code>). Optionally discretizes labels for balancing and partitions the dataset using <code>smallest_assignment</code> into train/test/validation subsets. Prints warnings if achieved proportions deviate significantly from expectations.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame containing the entities to cluster and partition.</p> required <code>sim_df</code> <code>DataFrame</code> <p>Similarity matrix provided as a Polars DataFrame, used to augment UMAP clustering.</p> required <code>field_name</code> <code>str</code> <p>Optional name of a column with feature vectors used by UMAP. If <code>None</code>, clustering relies entirely on <code>sim_df</code>, defaults to <code>None</code>.</p> <code>None</code> <code>label_name</code> <code>str</code> <p>Optional column name containing labels used for balancing partitions, defaults to <code>None</code>.</p> <code>None</code> <code>test_size</code> <code>float</code> <p>Proportion of entities to allocate to the test subset, defaults to <code>0.0</code>.</p> <code>0.0</code> <code>valid_size</code> <code>float</code> <p>Proportion of entities to allocate to the validation subset, defaults to <code>0.0</code>.</p> <code>0.0</code> <code>threshold</code> <code>float</code> <p>Threshold used by the UMAP graph clustering step, defaults to <code>0.3</code>.</p> <code>0.3</code> <code>verbose</code> <code>int</code> <p>Verbosity level. When <code>&gt; 2</code> prints detailed proportions, defaults to <code>2</code>.</p> <code>2</code> <code>n_clusters</code> <code>int</code> <p>Desired number of clusters to generate, defaults to <code>10</code>.</p> <code>10</code> <code>n_neighbors</code> <code>int</code> <p>UMAP <code>n_neighbors</code> parameter, defaults to <code>15</code>.</p> <code>15</code> <code>n_components</code> <code>int</code> <p>Number of UMAP embedding dimensions, defaults to <code>2</code>.</p> <code>2</code> <code>n_pcs</code> <code>int</code> <p>Number of principal components to compute before UMAP, defaults to <code>50</code>.</p> <code>50</code> <code>min_dist</code> <code>float</code> <p>UMAP <code>min_dist</code> parameter controlling embedding tightness, defaults to <code>0.1</code>.</p> <code>0.1</code> <code>boolean_out</code> <code>bool</code> <p>Whether to convert the similarity thresholding output to boolean values, defaults to <code>True</code>.</p> <code>True</code> <code>n_bins</code> <code>int</code> <p>Number of bins used when discretizing labels for balancing, defaults to <code>10</code>.</p> <code>10</code> <p>Returns:</p> Type Description <code>Union[     Tuple[List[int], List[int], List[int], np.ndarray],     Tuple[List[int], List[int], np.ndarray] ]</code> <p>If <code>valid_size &gt; 0</code> returns train, test, valid subsets plus cluster assignments. Otherwise returns train, test subsets plus cluster assignments.</p>"},{"location":"partition/#hestia.partition.smallest_assignment","title":"<code>smallest_assignment(clusters, labels, size, valid_size, test_size)</code>","text":"<p>Assigns iteratively the smallest subclusters to the test subset, until it reaches the desired size.</p> <p>Parameters:</p> Name Type Description Default <code>list_ids</code> <code>list[str]</code> <p>Ordered list of item identifiers to assign.</p> required <code>partition_lengths</code> <code>ndarray</code> <p>Desired number of items for each partition.</p> required <code>max_length_per_partition</code> <code>(int, optional)</code> <p>Maximum allowed size for any partition, values in <code>partition_lengths</code> exceeding this are clipped, defaults to <code>100000000</code>.</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray, np.ndarray, np.ndarray]</code> <p>The indices for training, testing and valiation subsets. In that order.</p>"},{"location":"partition/#hestia.partition.umap_original","title":"<code>umap_original(df, field_name, label_name=None, test_size=0.0, valid_size=0.0, threshold=0.3, verbose=2, n_clusters=10, n_neighbors=15, n_components=2, n_pcs=50, min_dist=0.1, radius=2, bits=1024, n_bins=10, **kwargs)</code>","text":"<p>Computes UMAP embeddings using the specified feature column, generates cluster assignments, discretizes labels (if provided), and then distributes the instances into train/test/validation partitions using the <code>smallest_assignment</code> strategy. Optional warnings are printed if resulting partitions deviate significantly from expected proportions.</p> <p>Reference: Guo Q, Hernandez-Hernandez S, Ballester PJ. UMAP-based clustering split for rigorous evaluation of AI models for virtual screening on cancer cell lines. Journal of Cheminformatics. 2025 Jun 10;17(1):94.</p> <p>Code adapted from Pat Walter's useful rdkit utils Github Repository: https://github.com/PatWalters/useful_rdkit_utils</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame containing entities to cluster and partition.</p> required <code>field_name</code> <code>str</code> <p>Name of the column containing the features used by UMAP.</p> required <code>label_name</code> <code>str</code> <p>Optional column name with labels used for balancing partitions, defaults to <code>None</code>.</p> <code>None</code> <code>test_size</code> <code>float</code> <p>Proportion of entities to place in the test subset, defaults to <code>0.0</code>.</p> <code>0.0</code> <code>valid_size</code> <code>float</code> <p>Proportion of entities to place in the validation subset, defaults to <code>0.0</code>.</p> <code>0.0</code> <code>threshold</code> <code>float</code> <p>Threshold applied during UMAP-based graph clustering, defaults to <code>0.3</code>.</p> <code>0.3</code> <code>verbose</code> <code>int</code> <p>Verbosity level. Values <code>&gt; 2</code> print partition proportions, defaults to <code>2</code>.</p> <code>2</code> <code>n_clusters</code> <code>int</code> <p>Desired number of clusters to generate using UMAP, defaults to <code>10</code>.</p> <code>10</code> <code>n_neighbors</code> <code>int</code> <p>UMAP <code>n_neighbors</code> parameter, defaults to <code>15</code>.</p> <code>15</code> <code>n_components</code> <code>int</code> <p>Number of UMAP embedding dimensions, defaults to <code>2</code>.</p> <code>2</code> <code>n_pcs</code> <code>int</code> <p>Number of principal components to compute before UMAP, defaults to <code>50</code>.</p> <code>50</code> <code>min_dist</code> <code>float</code> <p>UMAP <code>min_dist</code> parameter controlling embedding tightness, defaults to <code>0.1</code>.</p> <code>0.1</code> <code>radius</code> <code>int</code> <p>Radius value used by the UMAP graph construction, defaults to <code>2</code>.</p> <code>2</code> <code>bits</code> <code>int</code> <p>Dimensionality of any hashing step used for vector representations, defaults to <code>1024</code>.</p> <code>1024</code> <code>n_bins</code> <code>int</code> <p>Number of bins used when discretizing labels for balancing, defaults to <code>10</code>.</p> <code>10</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments passed to underlying UMAP or clustering routines.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[     Tuple[List[int], List[int], List[int], np.ndarray],     Tuple[List[int], List[int], np.ndarray] ]</code> <p>If <code>valid_size &gt; 0</code> returns train, test, valid partitions plus cluster assignments. Otherwise returns train, test partitions plus cluster assignments.</p>"},{"location":"reduction/","title":"Similarity reduction","text":""},{"location":"similarity/","title":"Similarity calculation","text":""},{"location":"similarity/#hestia.similarity.embedding_similarity","title":"<code>embedding_similarity(query_embds, target_embds=None, sim_function='cosine', threads=cpu_count(), threshold=0.0, verbose=3, save_alignment=False, filename=None, **kwargs)</code>","text":"<p>Calculates pairwise similarity between embeddings in <code>query_embds</code> and <code>target_embds</code> using specified similarity functions. Supports parallel processing to handle large datasets efficiently.</p> <p>Parameters:</p> Name Type Description Default <code>query_embds</code> <code>ndarray</code> <p>Array of embeddings for the query set. Each row should represent a single embedding.</p> required <code>target_embds</code> <code>Optional[ndarray]</code> <p>Array of embeddings for the target set. If None, self-comparison of <code>query_embds</code>  is performed.</p> <code>None</code> <code>sim_function</code> <code>Union[str, Callable]</code> <p>Similarity function to use for pairwise comparison. Default is 'cosine'. Can be either  a string specifying a built-in function or a custom callable.</p> <code>'cosine'</code> <code>threads</code> <code>int</code> <p>Number of CPU threads for parallel processing. Defaults to the system CPU count.</p> <code>cpu_count()</code> <code>threshold</code> <code>float</code> <p>Minimum similarity score required to include a pair in the results. Defaults to 0.0.</p> <code>0.0</code> <code>save_alignment</code> <code>bool</code> <p>If True, saves the alignment results to a compressed CSV file.</p> <code>False</code> <code>filename</code> <code>str</code> <p>Name for the output file if <code>save_alignment</code> is True. Defaults to a timestamp if None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for compatibility.</p> <code>{}</code> <p>Returns:</p> Type Description <code>pl.DataFrame</code> <p>DataFrame with columns <code>query</code>, <code>target</code>, and <code>metric</code>, where each row represents a pairwise  similarity score above the specified <code>threshold</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If any exception occurs in a thread during similarity calculation.</p> <code>KeyError</code> <p>If the specified <code>sim_function</code> is not supported.</p>"},{"location":"similarity/#hestia.similarity.molecular_similarity","title":"<code>molecular_similarity(df_query, df_target=None, field_name='smiles', sim_function='jaccard', fingerprint='mapc', bits=1024, radius=2, threshold=0.0, threads=cpu_count(), verbose=3, save_alignment=False, filename=None, **kwargs)</code>","text":"<p>Calculates pairwise molecular similarity between query and target molecules using specified fingerprint and similarity functions. Uses RDKit for molecular fingerprinting and similarity calculations.</p> <p>Parameters:</p> Name Type Description Default <code>df_query</code> <code>DataFrame</code> <p>DataFrame containing SMILES strings of query molecules. Each row should have a column  specified by <code>field_name</code> with SMILES strings.</p> required <code>df_target</code> <code>DataFrame</code> <p>DataFrame containing SMILES strings of target molecules. If None, self-comparison of  <code>df_query</code> is performed.</p> <code>None</code> <code>field_name</code> <code>str</code> <p>Column name in <code>df_query</code> and <code>df_target</code> that contains SMILES strings. Defaults to 'smiles'.</p> <code>'smiles'</code> <code>sim_function</code> <code>str</code> <p>Similarity function to use for pairwise comparison. Options include 'tanimoto', 'dice', 'sokal', 'rogot-goldberg', 'jaccard', 'canberra', and 'cosine'. Defaults to 'jaccard'.</p> <code>'jaccard'</code> <code>fingerprint</code> <code>str</code> <p>Type of fingerprint to use, options are 'ecfp' (Extended-Connectivity Fingerprint), 'maccs' (MACCS keys), 'mapc' (requires the mapchiral package), or `lipinski. Defaults to 'mapc'.</p> <code>'mapc'</code> <code>bits</code> <code>int</code> <p>Size of the fingerprint bit vector, applicable to <code>ecfp</code> and <code>mapc</code>. Defaults to 1024.</p> <code>1024</code> <code>radius</code> <code>int</code> <p>Radius for the ECFP fingerprint, applicable to <code>ecfp</code> and <code>mapc</code>. Defaults to 2.</p> <code>2</code> <code>threshold</code> <code>float</code> <p>Minimum similarity score required to include a pair in the results. Defaults to 0.0.</p> <code>0.0</code> <code>threads</code> <code>int</code> <p>Number of CPU threads for parallel processing. Defaults to the system CPU count.</p> <code>cpu_count()</code> <code>verbose</code> <code>int</code> <p>Verbosity level, where higher values increase output detail. Defaults to 0.</p> <code>3</code> <code>save_alignment</code> <code>bool</code> <p>If True, saves the alignment results to a compressed CSV file.</p> <code>False</code> <code>filename</code> <code>str</code> <p>Name for the output file if <code>save_alignment</code> is True. Defaults to a timestamp if None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for compatibility.</p> <code>{}</code> <p>Returns:</p> Type Description <code>pl.DataFrame</code> <p>DataFrame with columns <code>query</code>, <code>target</code>, and <code>metric</code>, where each row represents a pairwise  similarity score above the specified <code>threshold</code>.</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If RDKit (or mapchiral, if used with 'mapc') is not installed.</p> <code>ValueError</code> <p>If <code>field_name</code> is missing from <code>df_query</code> or <code>df_target</code>.</p> <code>NotImplementedError</code> <p>If <code>sim_function</code> is not supported by the function.</p>"},{"location":"similarity/#hestia.similarity.protein_structure_similarity","title":"<code>protein_structure_similarity(df_query, df_target=None, field_name='structure', prefilter=True, denominator='shortest', representation='3di+aa', threshold=0.0, threads=cpu_count(), verbose=0, save_alignment=False, filename=None, **kwargs)</code>","text":"<p>Calculates pairwise structural similarity between query and target protein structures using Foldseek. Supports alignment based on various representations, including 3D alignment, TM alignment, and  combined 3D and amino acid alignments.</p> <p>Parameters:</p> Name Type Description Default <code>df_query</code> <code>DataFrame</code> <p>DataFrame containing query protein structures. Each row should have a column  specified by <code>field_name</code> with paths to PDB files.</p> required <code>df_target</code> <code>DataFrame</code> <p>DataFrame containing target protein structures, with each row holding paths to  PDB files in <code>field_name</code>. If None, self-comparison of <code>df_query</code> is performed.</p> <code>None</code> <code>field_name</code> <code>str</code> <p>Column name in <code>df_query</code> and <code>df_target</code> with paths to PDB structure files. Defaults to 'structure'.</p> <code>'structure'</code> <code>prefilter</code> <code>bool</code> <p>Enables prefiltering to reduce computation. Defaults to True.</p> <code>True</code> <code>denominator</code> <code>str</code> <p>Determines similarity normalization, using \"shortest\" (default), \"longest\",  or the number of aligned residues (<code>n_aligned</code>).</p> <code>'shortest'</code> <code>representation</code> <code>str</code> <p>Alignment representation mode, with options '3di', 'TM', or '3di+aa'.  Defaults to '3di+aa'.</p> <code>'3di+aa'</code> <code>threshold</code> <code>float</code> <p>Minimum similarity metric required to include an alignment in the results. Defaults to 0.0.</p> <code>0.0</code> <code>threads</code> <code>int</code> <p>Number of CPU threads for parallel processing. Defaults to system CPU count.</p> <code>cpu_count()</code> <code>verbose</code> <code>int</code> <p>Verbosity level for process logging, where higher values increase output detail.</p> <code>0</code> <code>save_alignment</code> <code>bool</code> <p>If True, saves alignment results to a compressed CSV file.</p> <code>False</code> <code>filename</code> <code>str</code> <p>Name for the output file if <code>save_alignment</code> is True. Defaults to a timestamp if None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for compatibility.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[pd.DataFrame, np.ndarray]</code> <p>DataFrame with columns <code>query</code>, <code>target</code>, and <code>metric</code>, where each row represents an alignment  with a similarity metric above <code>threshold</code>. Returns the metric value determined by <code>representation</code>.</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If Foldseek is not installed or accessible in the system PATH.</p> <code>ValueError</code> <p>If <code>field_name</code> is missing from <code>df_query</code> or <code>df_target</code>.</p>"},{"location":"similarity/#hestia.similarity.sequence_similarity_mmseqs","title":"<code>sequence_similarity_mmseqs(df_query, df_target=None, field_name='sequence', prefilter=True, denominator='shortest', threads=cpu_count(), is_nucleotide=False, threshold=0.0, verbose=0, save_alignment=False, filename=None)</code>","text":"<p>Calculate pairwise sequence similarity between query and target sequences using MMSeqs2,  with optional prefiltering for efficiency. Designed for parallel execution and customizable  alignment parameters.</p> <p>Parameters:</p> Name Type Description Default <code>df_query</code> <code>DataFrame</code> <p>DataFrame containing the query sequences. Each row should have a column  specified by <code>field_name</code> with sequence strings.</p> required <code>df_target</code> <code>DataFrame</code> <p>DataFrame with target sequences, where each row has a <code>field_name</code> column  containing sequence strings. If None, <code>df_query</code> will be used for self-comparisons.</p> <code>None</code> <code>field_name</code> <code>str</code> <p>Column name in <code>df_query</code> and <code>df_target</code> holding the sequence data to be aligned. Defaults to 'sequence'.</p> <code>'sequence'</code> <code>prefilter</code> <code>bool</code> <p>If True, performs an initial filtering step to reduce the number of comparisons.</p> <code>True</code> <code>denominator</code> <code>str</code> <p>Determines how similarity is calculated, using either \"shortest\" (default),  \"longest\", or the number of aligned residues (<code>n_aligned</code>).</p> <code>'shortest'</code> <code>threads</code> <code>int</code> <p>Number of threads for parallel processing. Defaults to system CPU count.</p> <code>cpu_count()</code> <code>is_nucleotide</code> <code>bool</code> <p>Set to True if sequences are nucleotide-based. Defaults to False (for protein sequences).</p> <code>False</code> <code>threshold</code> <code>float</code> <p>Minimum similarity metric for alignment entries to be included in the output. Defaults to 0.0.</p> <code>0.0</code> <code>verbose</code> <code>int</code> <p>Verbosity level, where 0 is silent and higher levels increase detail in logging.</p> <code>0</code> <code>save_alignment</code> <code>bool</code> <p>If True, saves the resulting DataFrame to a compressed CSV file.</p> <code>False</code> <code>filename</code> <code>str</code> <p>Filename for saving the alignment results if <code>save_alignment</code> is True. If None, a timestamp is used as the filename.</p> <code>None</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>DataFrame with columns <code>query</code>, <code>target</code>, and <code>metric</code>, where each row represents an alignment result with similarity metric above the <code>threshold</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If MMSeqs2 is not installed or is unavailable in the system PATH.</p> <code>ValueError</code> <p>If <code>field_name</code> is not found in <code>df_query</code> or <code>df_target</code>.</p>"},{"location":"similarity/#hestia.similarity.sequence_similarity_needle","title":"<code>sequence_similarity_needle(df_query, df_target=None, field_name='sequence', denominator='shortest', is_nucleotide=False, config=None, threshold=0.0, threads=cpu_count(), verbose=0, save_alignment=False, filename=None)</code>","text":"<p>Calculate pairwise sequence similarity between query and target sequences using the  EMBOSS <code>needleall</code> tool. This function is designed for efficient parallel processing  and supports custom alignment parameters.</p> <p>Parameters:</p> Name Type Description Default <code>df_query</code> <code>DataFrame</code> <p>DataFrame containing the query sequences. Each row should have a column  specified by <code>field_name</code> that contains sequence strings.</p> required <code>df_target</code> <code>DataFrame</code> <p>DataFrame containing the target sequences, with a column specified by  <code>field_name</code> containing sequence strings. If None, <code>df_query</code> will  be used as the target DataFrame, performing self-comparisons.</p> <code>None</code> <code>field_name</code> <code>str</code> <p>Name of the column in <code>df_query</code> and <code>df_target</code> containing the  sequence data to be compared. Defaults to 'sequence'.</p> <code>'sequence'</code> <code>denominator</code> <code>str</code> <p>Determines how similarity is calculated; options are \"shortest\"  (default), \"longest\", or \"average\" sequence length between pairs.</p> <code>'shortest'</code> <code>is_nucleotide</code> <code>bool</code> <p>Indicates if the sequences are nucleotide sequences. If False,  assumes sequences are protein-based.</p> <code>False</code> <code>config</code> <code>dict</code> <p>Dictionary of EMBOSS <code>needleall</code> alignment parameters, such as  <code>gapopen</code>, <code>gapextend</code>, etc. If None, default configuration is used.</p> <code>None</code> <code>threshold</code> <code>float</code> <p>Minimum similarity metric required for alignment entries to be included  in the output. Defaults to 0.0.</p> <code>0.0</code> <code>threads</code> <code>int</code> <p>Number of threads to use for parallel processing. Defaults to system  CPU count.</p> <code>cpu_count()</code> <code>verbose</code> <code>int</code> <p>Verbosity level of function output; 0 is silent, higher numbers increase  output detail.</p> <code>0</code> <code>save_alignment</code> <code>bool</code> <p>If True, saves the resulting DataFrame to a compressed CSV file.</p> <code>False</code> <code>filename</code> <code>str</code> <p>Filename for saving the alignment results if <code>save_alignment</code> is True.  If None, a timestamp will be used as the filename.</p> <code>None</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>DataFrame with columns <code>query</code>, <code>target</code>, and <code>metric</code>, where each row  represents a sequence alignment result, filtered by the specified <code>threshold</code>.</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>Raised if the <code>needleall</code> tool from EMBOSS is not installed.</p> <code>ValueError</code> <p>Raised if <code>field_name</code> is missing from <code>df_query</code> or <code>df_target</code>.</p> <code>RuntimeError</code> <p>Raised if any alignment job encounters an exception during processing.</p>"},{"location":"similarity/#hestia.similarity.sequence_similarity_peptides","title":"<code>sequence_similarity_peptides(df_query, df_target=None, field_name='sequence', denominator='shortest', threads=cpu_count(), threshold=0.0, verbose=0, save_alignment=False, filename=None)</code>","text":"<p>Calculates pairwise sequence similarity between query and target peptide sequences using MMSeqs2. Sequences are divided into \"small,\" \"medium,\" and \"normal\" categories based on length, and  each category is aligned with a specific method for optimal recall.</p> <ul> <li>_small_alignment: For sequences with 8 or fewer residues, checks if one sequence is a subsequence of the other.</li> <li>_medium_alignment: For sequences between 9 and 20 residues, uses a lower threshold with MMSeqs2 to filter alignments.</li> <li>_normal_alignment: For sequences longer than 20 residues, performs full alignments with MMSeqs2.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>df_query</code> <code>DataFrame</code> <p>DataFrame containing the query peptide sequences. Each row should have a column  specified by <code>field_name</code> with peptide sequence strings.</p> required <code>df_target</code> <code>Optional[DataFrame]</code> <p>DataFrame with target peptide sequences, where each row has a <code>field_name</code> column  containing sequence strings. If None, <code>df_query</code> will be used for self-comparisons.</p> <code>None</code> <code>field_name</code> <code>Optional[str]</code> <p>Column name in <code>df_query</code> and <code>df_target</code> holding the sequence data to be aligned. Defaults to 'sequence'.</p> <code>'sequence'</code> <code>denominator</code> <code>Optional[str]</code> <p>Determines how similarity is calculated, using either \"shortest\" (default),  \"longest\", or the number of aligned residues (<code>n_aligned</code>).</p> <code>'shortest'</code> <code>threads</code> <code>Optional[int]</code> <p>Number of threads for parallel processing. Defaults to system CPU count.</p> <code>cpu_count()</code> <code>threshold</code> <code>Optional[float]</code> <p>Minimum similarity metric for alignment entries to be included in the output. Defaults to 0.0.</p> <code>0.0</code> <code>verbose</code> <code>Optional[int]</code> <p>Verbosity level, where 0 is silent and higher levels increase detail in logging.</p> <code>0</code> <code>save_alignment</code> <code>Optional[bool]</code> <p>If True, saves the resulting DataFrame to a compressed CSV file.</p> <code>False</code> <code>filename</code> <code>Optional[int]</code> <p>Filename for saving the alignment results if <code>save_alignment</code> is True.  If None, a timestamp is used as the filename.</p> <code>None</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>DataFrame with columns <code>query</code>, <code>target</code>, and <code>metric</code>, where each row represents  an alignment result with similarity metric above the <code>threshold</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If MMSeqs2 is not installed or is unavailable in the system PATH.</p> <code>ValueError</code> <p>If <code>field_name</code> is not found in <code>df_query</code> or <code>df_target</code>.</p>"},{"location":"similarity/#hestia.similarity.sim_df2mtx","title":"<code>sim_df2mtx(sim_df, size_query=None, size_target=None, threshold=0.0, filter_smaller=True, boolean_out=True)</code>","text":"<p>Converts a DataFrame of similarity scores into a sparse matrix representation, optionally filtering  based on a similarity threshold and producing a boolean or numerical output.</p> <p>Parameters:</p> Name Type Description Default <code>sim_df</code> <code>Union[DataFrame, DataFrame]</code> <p>DataFrame containing similarity data with <code>query</code>, <code>target</code>, and <code>metric</code> columns.</p> required <code>size_query</code> <code>Optional[int]</code> <p>Total number of unique query indices, defining the first dimension of the matrix.  Defaults to the number of unique queries in <code>sim_df</code>.</p> <code>None</code> <code>size_target</code> <code>Optional[int]</code> <p>Total number of unique target indices, defining the second dimension of the matrix.  Defaults to <code>size_query</code>, assuming a square matrix.</p> <code>None</code> <code>threshold</code> <code>Optional[float]</code> <p>Similarity score threshold for filtering. Defaults to 0.0.</p> <code>0.0</code> <code>filter_smaller</code> <code>Optional[bool]</code> <p>If True, retains values above the threshold. If False, retains values below it.</p> <code>True</code> <code>boolean_out</code> <code>Optional[bool]</code> <p>If True, converts output to boolean values, representing presence/absence of similarity.  If False, retains original similarity values.</p> <code>True</code> <p>Returns:</p> Type Description <code>spr.csr_matrix</code> <p>Symmetric sparse matrix of filtered similarity scores, either in boolean or numerical format.</p>"}]}